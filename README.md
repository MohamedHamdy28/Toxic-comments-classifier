# Toxic-comments-classifier

This was is Natural Language Processing project undertaken at Innopolis University. Our goal was to build a system that can accurately classify toxic comments in online conversations into six categories: toxic, severe_toxic, obscene, threat, insult, and identity hate.

To finish this project we did:
- Data collection and preprocessing
- Implemented a baseline model contain Naive bayes and logistic regression
- Implemented a classifier using CNN
- Implemented a classifier using LSTM
- Implemented a classifier using BERT

At the end, the best preforming model was BERT.

You can find more information in our report attached to this repo.

